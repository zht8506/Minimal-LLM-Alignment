
\[ [English](README.md) | ä¸­æ–‡\]

ä¸€ä¸ªè½»é‡çº§çš„å¤§è¯­è¨€æ¨¡å‹å¯¹é½è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒSFTï¼ˆç›‘ç£å¾®è°ƒï¼‰å’ŒDPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰ç­‰ä¸»æµå¯¹é½æ–¹æ³•ã€‚

## ğŸ› ï¸ å®‰è£…è¦æ±‚

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- PyTorch 2.0+
- Transformers 4.20+
- CUDA 11.8+ (GPUè®­ç»ƒ)

### å®‰è£…ä¾èµ–
```bash
pip install torch transformers datasets accelerate wandb omegaconf
```

## ğŸ“Š è‡ªå®šä¹‰æ•°æ®æ„å»º

### 1. SFTæ•°æ®é›†æ ¼å¼

SFTæ•°æ®é›†ä½¿ç”¨å¯¹è¯æ ¼å¼ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ä¸€ä¸ªå¯¹è¯åºåˆ—ï¼š

```json
[
  {
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Describe a process of making crepes."
      },
      {
        "role": "assistant",
        "content": "Making crepes is an easy and delicious process! Here are step-by-step instructions..."
      }
    ]
  }
]
```

### 2. DPOæ•°æ®é›†æ ¼å¼

DPOæ•°æ®é›†åŒ…å«åå¥½å¯¹æ¯”ä¿¡æ¯ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
- `conversations`: å¯¹è¯ä¸Šä¸‹æ–‡
- `chosen`: åå¥½å›ç­”
- `rejected`: éåå¥½å›ç­”

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "How can I best prepare for a job interview?"
      }
    ],
    "chosen": {
      "from": "gpt",
      "value": "Preparing for a job interview requires a combination of research, practice, and self-reflection..."
    },
    "rejected": {
      "from": "gpt",
      "value": "Here are some tips to help you prepare for a job interview..."
    }
  }
]
```

### 3. æ•°æ®è½¬æ¢å·¥å…·

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. åŸºç¡€è®­ç»ƒ

#### SFTè®­ç»ƒ
```bash
python train.py example/pythia28-sft.yml
```

#### DPOè®­ç»ƒ
```bash
python train.py example/pythia28-dpo.yml
```

### 2. è‡ªå®šä¹‰é…ç½®

åˆ›å»ºè‡ªå®šä¹‰é…ç½®æ–‡ä»¶ï¼š

```yaml
# åŸºç¡€é…ç½®
seed: 0
exp_name: my_experiment
datasets: 
  - type: custom_dataset
    path: path/to/your/dataset.json

# è®­ç»ƒå‚æ•°
trainer: BasicTrainer
optimizer: AdamW
lr: 1e-5
total_batch_size: 16
gradient_accumulation_steps: 4
max_length: 512
n_epochs: 100

# æ¨¡å‹é…ç½®
model:
  name_or_path: your/model/path
  policy_dtype: float16

# æŸå¤±å‡½æ•°é…ç½®
loss:
  name: dpo  # æˆ– sft
  beta: 0.1  # DPOå‚æ•°
```

### 3. å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

```bash
python train.py config.yml --overrides lr=2e-5 batch_size=32
```

### 4. åˆ†å¸ƒå¼è®­ç»ƒ

ä½¿ç”¨FSDPè®­ç»ƒå™¨è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼š

```bash
python train.py config.yml --overrides trainer=FSDPTrainer
```

## ğŸ“ é…ç½®æ–‡ä»¶è¯¦è§£

### ä¸»è¦é…ç½®é¡¹

- **åŸºç¡€é…ç½®**: å®éªŒåç§°ã€éšæœºç§å­ã€è°ƒè¯•æ¨¡å¼
- **æ•°æ®é›†é…ç½®**: æ•°æ®é›†ç±»å‹ã€è·¯å¾„ã€åŠ è½½æ–¹å¼
- **è®­ç»ƒé…ç½®**: å­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ã€ä¼˜åŒ–å™¨ã€è®­ç»ƒæ­¥æ•°
- **æ¨¡å‹é…ç½®**: æ¨¡å‹è·¯å¾„ã€æ•°æ®ç±»å‹ã€æ£€æŸ¥ç‚¹åŠ è½½
- **æŸå¤±é…ç½®**: æŸå¤±å‡½æ•°ç±»å‹ã€å‚æ•°è®¾ç½®
- **è¾“å‡ºé…ç½®**: è¾“å‡ºç›®å½•ã€æ—¥å¿—è®°å½•ã€æ¨¡å‹ä¿å­˜

### ç¯å¢ƒå˜é‡

- `WANDB_CACHE_DIR`: WandBç¼“å­˜ç›®å½•
- `XDG_CACHE_HOME`: ä¸´æ—¶æ–‡ä»¶ç¼“å­˜ç›®å½•

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. æ¨¡å‹æ£€æŸ¥ç‚¹åŠ è½½

```yaml
model:
  archive: path/to/checkpoint.pt  # åŠ è½½é¢„è®­ç»ƒæƒé‡
```

### 2. æ¢¯åº¦ç´¯ç§¯

```yaml
gradient_accumulation_steps: 4  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
```

### 3. æ¿€æ´»æ£€æŸ¥ç‚¹

```yaml
activation_checkpointing: true  # å¯ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜
```

### 4. æ··åˆç²¾åº¦è®­ç»ƒ

```yaml
model:
  policy_dtype: bfloat16  # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
```

## ğŸ“ˆ ç›‘æ§å’Œè¯„ä¼°

### 1. WandBé›†æˆ

```yaml
wandb:
  enabled: true
  entity: your_entity
  project: "Minimal-LLM-Alignment"
```

### 2. TensorBoardæ”¯æŒ

```yaml
report_to_tensorboard: true
```

### 3. è¯„ä¼°é…ç½®

```yaml
do_first_eval: false
eval_every_steps: 100
n_eval_examples: 256
```
